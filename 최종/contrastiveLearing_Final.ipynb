{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torchvision import models, transforms\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# GPU 디바이스 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Early Stopping 클래스\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, checkpoint_path='./best_model.pth'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, loss, model):\n",
    "        if loss < self.best_loss:\n",
    "            self.best_loss = loss\n",
    "            self.counter = 0\n",
    "            torch.save(model.state_dict(), self.checkpoint_path)  # 체크포인트 저장\n",
    "            if self.verbose:\n",
    "                print(f\"Validation loss decreased. Saving model to {self.checkpoint_path}\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class DeepFakeDataset(Dataset):\n",
    "    def __init__(self, csv_path, root_dir, transform=None, frame_num=1):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.frame_num = frame_num\n",
    "        self.data['label'] = self.data['label'].apply(lambda x: 0 if x == 'FAKE' else 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = os.path.join(self.root_dir, self.data.iloc[idx, 0])\n",
    "        label = self.data.iloc[idx, 1]\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        target_frame = self.frame_num if self.frame_num <= frame_count else frame_count // 2\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)\n",
    "        ret, frame = cap.read()\n",
    "        cap.release()\n",
    "\n",
    "        if not ret:\n",
    "            raise RuntimeError(f\"Failed to read frame from video: {video_path}\")\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(frame)\n",
    "\n",
    "        if self.transform:\n",
    "            image1 = self.transform(image)\n",
    "            image2 = self.transform(image)\n",
    "        return image1, image2, label\n",
    "\n",
    "# 데이터 변환\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 데이터 로더 설정\n",
    "csv_path = './metadata.csv'\n",
    "root_dir = './train_data'\n",
    "train_dataset = DeepFakeDataset(csv_path, root_dir, transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# SimCLR 모델 정의\n",
    "class SimCLRModel(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(SimCLRModel, self).__init__()\n",
    "        self.encoder = base_model\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        features = torch.flatten(features, start_dim=1)\n",
    "        projected = self.projector(features)\n",
    "        return projected\n",
    "\n",
    "# ResNet18 기반 모델\n",
    "base_model = models.resnet18(pretrained=True)\n",
    "base_model = nn.Sequential(*list(base_model.children())[:-1])\n",
    "model = SimCLRModel(base_model).to(device)  # 모델을 GPU로 이동\n",
    "\n",
    "# NT-Xent 손실 함수\n",
    "def nt_xent_loss(features, temperature=0.5):\n",
    "    batch_size = features.shape[0]\n",
    "    labels = torch.cat([torch.arange(batch_size // 2) for _ in range(2)]).to(device)\n",
    "    similarity_matrix = F.cosine_similarity(features.unsqueeze(1), features.unsqueeze(0), dim=2)\n",
    "    mask = torch.eye(batch_size, dtype=torch.bool).to(device)\n",
    "    positives = similarity_matrix[mask].view(batch_size, -1)\n",
    "    negatives = similarity_matrix[~mask].view(batch_size, -1)\n",
    "    logits = torch.cat([positives, negatives], dim=1) / temperature\n",
    "    labels = torch.zeros(batch_size, dtype=torch.long).to(device)\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "# 학습 설정\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True, checkpoint_path='./best_model.pth')\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in tqdm(range(1000)):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for img1, img2, _ in train_loader:\n",
    "        img1, img2 = img1.to(device), img2.to(device)  # 데이터를 GPU로 이동\n",
    "        features1 = model(img1)\n",
    "        features2 = model(img2)\n",
    "        features = torch.cat([features1, features2], dim=0)\n",
    "        loss = nt_xent_loss(features)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/1000], Loss: {avg_loss:.4f}\")\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    if early_stopping(avg_loss, model):\n",
    "        print(\"Training stopped early\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# GPU 디바이스 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# SimCLR 모델 정의\n",
    "class SimCLRModel(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(SimCLRModel, self).__init__()\n",
    "        self.encoder = base_model\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        features = torch.flatten(features, start_dim=1)\n",
    "        projected = self.projector(features)\n",
    "        return projected\n",
    "\n",
    "# ResNet18 기반 모델 생성\n",
    "base_model = models.resnet18(pretrained=False)\n",
    "base_model = nn.Sequential(*list(base_model.children())[:-1])\n",
    "model = SimCLRModel(base_model).to(device)\n",
    "\n",
    "# 체크포인트 로드\n",
    "checkpoint_path = './best_model.pth'\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# 데이터 전처리 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 프레임 추출 및 변환\n",
    "def process_video(video_path, frame_num=1):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    target_frame = frame_num if frame_num <= frame_count else frame_count // 2\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    if not ret:\n",
    "        raise RuntimeError(f\"Failed to read frame from video: {video_path}\")\n",
    "    \n",
    "    # BGR -> RGB 변환\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(frame)\n",
    "\n",
    "    # 이미지 변환\n",
    "    image = transform(image)\n",
    "    return image.unsqueeze(0).to(device)  # 배치 차원 추가 후 GPU로 이동\n",
    "\n",
    "# 영상 예측 함수\n",
    "def predict(video_path):\n",
    "    try:\n",
    "        # 프레임 처리\n",
    "        image = process_video(video_path)\n",
    "\n",
    "        # 모델 추론\n",
    "        with torch.no_grad():\n",
    "            features = model.encoder(image)\n",
    "            output = features.view(features.size(0), -1)  # Flatten\n",
    "            prediction = torch.sigmoid(output).mean().item()\n",
    "\n",
    "        # FAKE 또는 REAL로 변환\n",
    "        label = \"FAKE\" if prediction < 0.5 else \"REAL\"\n",
    "        return label, prediction\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\", None\n",
    "\n",
    "# 폴더 내 모든 영상에 대해 예측\n",
    "def predict_folder(folder_path):\n",
    "    results = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path) and file_name.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "            label, confidence = predict(file_path)\n",
    "            results.append((file_name, label, confidence))\n",
    "            print(f\"{file_name}: {label} (Confidence: {confidence:.4f})\")\n",
    "    return results\n",
    "\n",
    "# 결과 저장 함수 (선택 사항)\n",
    "def save_results(results, output_file=\"results.csv\"):\n",
    "    import csv\n",
    "    with open(output_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"File Name\", \"Prediction\", \"Confidence\"])\n",
    "        writer.writerows(results)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "# 테스트용 코드\n",
    "folder_path = './train_data'  # 추론할 영상들이 있는 폴더 경로\n",
    "results = predict_folder(folder_path)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "save_results(results, output_file=\"prediction_results.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
